{"cells":[{"cell_type":"markdown","metadata":{"id":"a1Kzrl615yYN"},"source":["# 2021 폐플라스틱 이미지 객체 검출 예측 경진대회\n","- 팀: (10) 진짜이대로내요\n","- 구성원:\n","    - 윤준호 (팀장)\n","    - 최미래\n","- 제출물:\n","    - 소스코드 ipynb 파일 (Detectron2 사용)\n","    - 학습 가중치 pth 파일"]},{"cell_type":"markdown","metadata":{"id":"-bM0YBrW1tzw"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IVAimDIngRgk"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bACQiiUgmeI7"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zv-uLdRSm_ib"},"outputs":[],"source":["cd /content/drive/MyDrive/competition/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":26976,"status":"ok","timestamp":1639126602267,"user":{"displayName":"Philgineer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6byxR4CUvg70kzYC8cPgCtsx6xCht3ofjX1sJ8ZI=s64","userId":"03569868102892103784"},"user_tz":-540},"id":"FsePPpwZSmqt","outputId":"58af30b4-c6c3-4c20-d746-63d8ba67f25d"},"outputs":[],"source":["!pip install pyyaml==5.1\n","\n","import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":483,"status":"ok","timestamp":1639126602731,"user":{"displayName":"Philgineer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6byxR4CUvg70kzYC8cPgCtsx6xCht3ofjX1sJ8ZI=s64","userId":"03569868102892103784"},"user_tz":-540},"id":"ZyAvNCJMmvFF"},"outputs":[],"source":["# Import and setup logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# Import common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","from tqdm import tqdm\n","import random\n","import copy\n","\n","# Import Detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.structures import BoxMode\n","from detectron2.engine import DefaultPredictor, DefaultTrainer\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.utils.visualizer import ColorMode\n","from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader, build_detection_train_loader\n","from detectron2.data import build_detection_test_loader, build_detection_train_loader\n","from detectron2.data import detection_utils as utils\n","from detectron2.data import transforms as T\n","from detectron2.evaluation import COCOEvaluator"]},{"cell_type":"markdown","metadata":{"id":"b2bjrfb2LDeo"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1T_zi0THcVDZ"},"outputs":[],"source":["# Check bbox mode == (x, y ,w, h)\n","img = cv2.imread('./contest_dataset/train/image/PE/PE_074_148.jpg')\n","with open('./contest_dataset/train/annotation/PE/PE_074_148.json') as f:\n","    label = json.load(f)\n","    for instance in label['annotations']:\n","        x, y, w, h = instance['bbox']\n","        cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,255))\n","cv2_imshow(img)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":385,"status":"ok","timestamp":1639126651955,"user":{"displayName":"Philgineer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6byxR4CUvg70kzYC8cPgCtsx6xCht3ofjX1sJ8ZI=s64","userId":"03569868102892103784"},"user_tz":-540},"id":"s6gDuPDsp5xX"},"outputs":[],"source":["# Set classes\n","classes = ['pet', 'ps', 'pp', 'pe']\n","\n","# Exclude file due to prevent \"polygon\" error\n","excluded = ['PET_015_1358.json', 'PS_038_2948.json', 'PS_042_7482.json', 'PS_038_4646.json', # len(seg_bitmask) <= 4\n","            'PS_037_5996.json', 'PS_035_7052.json'] # len(seg_bitmask) % 2 != 0\n","\n","\n","def get_contest_dicts(data_dir):\n","    image_dir = os.path.join(data_dir, 'image')\n","    label_dir = os.path.join(data_dir, 'annotation')\n","\n","    dataset_all_classes = []\n","    for obj_cls in sorted(os.listdir(label_dir)):\n","        dataset_one_class = []\n","        for file_name in tqdm(os.listdir(os.path.join(label_dir, obj_cls))):\n","            if file_name in excluded:\n","                continue\n","            \n","            json_file = os.path.join(os.path.join(label_dir, obj_cls), file_name)\n","            with open(json_file) as f:\n","                label = json.load(f)\n","            record = {}\n","            record['file_name'] = os.path.join(image_dir, obj_cls, label['images'][0]['file_name'])\n","            for value in ['height', 'width']:\n","                record[value] = label['images'][0][value]\n","            record['image_id'] = label['images'][0]['id']\n","            \n","            objs = []\n","            for instance in label['annotations']:\n","                obj = {\n","                    \"bbox\": instance['bbox'],\n","                    \"bbox_mode\": BoxMode.XYWH_ABS,\n","                    \"segmentation\": instance['segmentation'],\n","                    # \"category_id\": instance['category_id']\n","                    \"category_id\": instance['category_id'] - 1\n","                }\n","                objs.append(obj)\n","\n","            record['annotations'] = objs\n","            dataset_one_class.append(record)\n","        dataset_all_classes.append(dataset_one_class)\n","    \n","    return dataset_all_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_zhfK05CEpW"},"outputs":[],"source":["# Dataset split\n","dataset_train = get_contest_dicts('./contest_dataset/train')\n","dataset_test = get_contest_dicts('./contest_dataset/test')\n","\n","train_dataset = []\n","val_dataset = []\n","test_dataset = []\n","\n","for cls in range(4):\n","    one_class = dataset_train[cls] + dataset_test[cls]\n","    random.shuffle(one_class)\n","    split_pt1 = int(len(one_class) * 0.7)\n","    split_pt2 = split_pt1 + int(len(one_class) * 0.15)\n","    train_dataset += one_class[:split_pt1]\n","    val_dataset += one_class[split_pt1:split_pt2]\n","    test_dataset += one_class[split_pt2:]"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":413,"status":"ok","timestamp":1639126895150,"user":{"displayName":"Philgineer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6byxR4CUvg70kzYC8cPgCtsx6xCht3ofjX1sJ8ZI=s64","userId":"03569868102892103784"},"user_tz":-540},"id":"Zp05NE9fzNIb"},"outputs":[],"source":["# Register dataset\n","train_test_dicts = {'train': train_dataset, 'val': val_dataset, 'test': test_dataset}\n","\n","for d in [\"train\", \"val\", \"test\"]:\n","    DatasetCatalog.register(\"contest_\" + d, lambda d=d: train_test_dicts[d])\n","    MetadataCatalog.get(\"contest_\" + d).set(thing_classes=classes)\n","contest_metadata = MetadataCatalog.get(\"contest_train\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UkNbUzUOLYf0"},"outputs":[],"source":["# Verify registered dataset\n","dataset_dicts = test_dataset\n","for d in random.sample(dataset_dicts, 3):\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=contest_metadata, scale=0.5)\n","    out = visualizer.draw_dataset_dict(d)\n","    cv2_imshow(out.get_image()[:, :, ::-1])\n","    print(d[\"file_name\"])"]},{"cell_type":"markdown","metadata":{"id":"F_cQfhQUU0be"},"source":["## Model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1639126919720,"user":{"displayName":"Philgineer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6byxR4CUvg70kzYC8cPgCtsx6xCht3ofjX1sJ8ZI=s64","userId":"03569868102892103784"},"user_tz":-540},"id":"eqekjkjrQMnZ"},"outputs":[],"source":["# Data augmentation\n","def custom_mapper(dataset_dict):\n","    dataset_dict = copy.deepcopy(dataset_dict)\n","    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n","    transform_list = [T.Resize((1024,1024)),\n","                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n","                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n","                      T.RandomBrightness(0.6, 1.4),\n","                      T.RandomContrast(0.6, 1.4),\n","                      T.RandomSaturation(0.6, 1.4)\n","                      ]\n","    image, transforms = T.apply_transform_gens(transform_list, image)\n","    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n","\n","    annos = [\n","        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n","        for obj in dataset_dict.pop(\"annotations\")\n","    ]\n","    instances = utils.annotations_to_instances(annos, image.shape[:2])\n","    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n","\n","    return dataset_dict\n","\n","\n","# Custom trainer for COCO format dataset\n","class COCOTrainer(DefaultTrainer):\n","\n","    @classmethod\n","    def build_train_loader(cls, cfg):\n","        return build_detection_train_loader(cfg, mapper=custom_mapper)\n","\n","    @classmethod\n","    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","\n","        if output_folder is None:\n","            os.makedirs(\"coco_eval\", exist_ok=True)\n","            output_folder = \"coco_eval\"\n","\n","        return COCOEvaluator(dataset_name, cfg, False, output_folder)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":461,"status":"ok","timestamp":1639140415277,"user":{"displayName":"Philgineer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6byxR4CUvg70kzYC8cPgCtsx6xCht3ofjX1sJ8ZI=s64","userId":"03569868102892103784"},"user_tz":-540},"id":"QU1VoFNwYfaV"},"outputs":[],"source":["# Pretrained model\n","model_yaml = \"COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml\"\n","\n","# Customize model structure\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(model_yaml))\n","cfg.DATASETS.TRAIN = (\"contest_train\",)\n","cfg.DATASETS.TEST = (\"contest_val\",)\n","cfg.TEST.EVAL_PERIOD = 500\n","cfg.DATALOADER.NUM_WORKERS = 4\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_yaml)\n","cfg.SOLVER.IMS_PER_BATCH = 4                                # batch size\n","cfg.SOLVER.BASE_LR = 0.0001\n","cfg.SOLVER.MAX_ITER = 5000\n","cfg.SOLVER.STEPS = (2000, 4000)                                  # decay learning rate\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512              # rpn proposal subset size for loss calculation\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n","cfg.MODEL.BACKBONE.FREEZE_AT = 0                            # freeze only stem\n","cfg.SOLVER.CHECKPOINT_PERIOD = 500\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"u4is1jLyYIsk"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7unkuuiqLdqd"},"outputs":[],"source":["trainer = COCOTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBXeH8UXFcqU"},"outputs":[],"source":["# Tensorboard training log\n","%load_ext tensorboard\n","%tensorboard --logdir output"]},{"cell_type":"markdown","metadata":{"id":"0e4vdDIOXyxF"},"source":["## Inference\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ya5nEuMELeq8"},"outputs":[],"source":["weight_path = \"model_weight.pth\"\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, weight_path)\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","predictor = DefaultPredictor(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U5LhISJqWXgM"},"outputs":[],"source":["for d in random.sample(test_dataset, 10):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=contest_metadata, \n","                   scale=0.5, \n","                   instance_mode=ColorMode.IMAGE_BW\n","    )\n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(out.get_image()[:, :, ::-1])\n","    print(d[\"file_name\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h9tECBQCvMv3"},"outputs":[],"source":["evaluator = COCOEvaluator(\"contest_test\", output_dir=\"./output\")\n","val_loader = build_detection_test_loader(cfg, \"contest_test\")\n","print(inference_on_dataset(predictor.model, val_loader, evaluator))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["-bM0YBrW1tzw","b2bjrfb2LDeo","F_cQfhQUU0be","u4is1jLyYIsk","0e4vdDIOXyxF"],"name":"detectron2_train.ipynb","provenance":[{"file_id":"16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5","timestamp":1638623817940}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
